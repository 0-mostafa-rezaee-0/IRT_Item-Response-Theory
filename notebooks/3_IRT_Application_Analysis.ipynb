{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "<h1>IRT Simulation and Analysis</h1>\n",
        "</div>\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates advanced IRT concepts through simulation and analysis. It covers:\n",
        "\n",
        "1. **IRT Probability Functions**: Understanding how ability and item parameters interact\n",
        "2. **Item Characteristic Curves**: Visualizing how items behave across ability levels\n",
        "3. **Information Functions**: Measuring item quality and precision\n",
        "4. **Adaptive Testing**: Simulating intelligent test administration\n",
        "5. **Convergence Analysis**: Understanding how ability estimates improve over time\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- How IRT models work in practice\n",
        "- The relationship between ability, difficulty, and probability\n",
        "- How to create informative visualizations\n",
        "- Principles of adaptive testing\n",
        "- Methods for ability estimation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import Required Libraries\n",
        "\n",
        "Let's import all necessary libraries for our IRT simulation and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Core IRT Functions\n",
        "\n",
        "Let's implement the fundamental IRT functions that we'll use throughout our analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def irt_probability(theta, b, a=1.0, c=0.0):\n",
        "    \"\"\"\n",
        "    Calculate the probability of a correct response using IRT models.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    theta : float or array\n",
        "        Ability parameter(s)\n",
        "    b : float\n",
        "        Item difficulty parameter\n",
        "    a : float, optional\n",
        "        Item discrimination parameter (default=1.0 for 1PL model)\n",
        "    c : float, optional\n",
        "        Item guessing parameter (default=0.0 for 1PL/2PL models)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    p : float or array\n",
        "        Probability of correct response\n",
        "    \"\"\"\n",
        "    # 3PL model: P(correct) = c + (1-c) / (1 + exp(-a(theta-b)))\n",
        "    return c + (1 - c) / (1 + np.exp(-a * (theta - b)))\n",
        "\n",
        "def item_information(theta, b, a=1.0, c=0.0):\n",
        "    \"\"\"\n",
        "    Calculate the item information function.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    theta : float or array\n",
        "        Ability parameter(s)\n",
        "    b, a, c : float\n",
        "        Item parameters\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    info : float or array\n",
        "        Item information at given ability level(s)\n",
        "    \"\"\"\n",
        "    p = irt_probability(theta, b, a, c)\n",
        "    q = 1 - p\n",
        "    return (a**2) * ((p - c)**2) / ((1 - c)**2) * (q / p)\n",
        "\n",
        "def simulate_response(theta, b, a=1.0, c=0.0):\n",
        "    \"\"\"\n",
        "    Simulate a response to an item based on IRT probability.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    response : int\n",
        "        1 for correct, 0 for incorrect\n",
        "    \"\"\"\n",
        "    p = irt_probability(theta, b, a, c)\n",
        "    return np.random.binomial(1, p)\n",
        "\n",
        "print(\"Core IRT functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Item Characteristic Curves (ICCs)\n",
        "\n",
        "Let's create visualizations showing how different item parameters affect the probability of correct responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive ICC visualizations\n",
        "theta_range = np.linspace(-4, 4, 100)\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Effect of difficulty (b) parameter\n",
        "ax = axes[0, 0]\n",
        "difficulty_levels = [-2, -1, 0, 1, 2]\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(difficulty_levels)))\n",
        "\n",
        "for i, b in enumerate(difficulty_levels):\n",
        "    p = irt_probability(theta_range, b=b)\n",
        "    ax.plot(theta_range, p, label=f'b = {b}', color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Effect of Difficulty Parameter (1PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Probability of Correct Response', fontsize=12)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "# 2. Effect of discrimination (a) parameter\n",
        "ax = axes[0, 1]\n",
        "discrimination_levels = [0.5, 1.0, 1.5, 2.0]\n",
        "colors = plt.cm.plasma(np.linspace(0, 1, len(discrimination_levels)))\n",
        "\n",
        "for i, a in enumerate(discrimination_levels):\n",
        "    p = irt_probability(theta_range, b=0, a=a)\n",
        "    ax.plot(theta_range, p, label=f'a = {a}', color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Effect of Discrimination Parameter (2PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Probability of Correct Response', fontsize=12)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "# 3. Effect of guessing (c) parameter\n",
        "ax = axes[1, 0]\n",
        "guessing_levels = [0.0, 0.1, 0.2, 0.25]\n",
        "colors = plt.cm.inferno(np.linspace(0, 1, len(guessing_levels)))\n",
        "\n",
        "for i, c in enumerate(guessing_levels):\n",
        "    p = irt_probability(theta_range, b=0, a=1, c=c)\n",
        "    ax.plot(theta_range, p, label=f'c = {c}', color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Effect of Guessing Parameter (3PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Probability of Correct Response', fontsize=12)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "# 4. Combined effect - 3PL model with different parameter combinations\n",
        "ax = axes[1, 1]\n",
        "item_configs = [\n",
        "    {'b': -1, 'a': 1.5, 'c': 0.0, 'label': 'Easy, High Discrim., No Guess'},\n",
        "    {'b': 0, 'a': 1.0, 'c': 0.1, 'label': 'Medium, Med Discrim., Low Guess'},\n",
        "    {'b': 1, 'a': 0.8, 'c': 0.2, 'label': 'Hard, Low Discrim., High Guess'},\n",
        "    {'b': 0, 'a': 2.0, 'c': 0.05, 'label': 'Medium, Very High Discrim., Low Guess'}\n",
        "]\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(item_configs)))\n",
        "\n",
        "for i, config in enumerate(item_configs):\n",
        "    p = irt_probability(theta_range, b=config['b'], a=config['a'], c=config['c'])\n",
        "    ax.plot(theta_range, p, label=config['label'], color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Combined Parameter Effects (3PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Probability of Correct Response', fontsize=12)\n",
        "ax.legend(fontsize=9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Item Characteristic Curves generated successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Information Functions\n",
        "\n",
        "Information functions tell us how much information an item provides at different ability levels. This is crucial for adaptive testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create information function visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Information functions for different difficulties\n",
        "ax = axes[0, 0]\n",
        "difficulty_levels = [-2, -1, 0, 1, 2]\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(difficulty_levels)))\n",
        "\n",
        "for i, b in enumerate(difficulty_levels):\n",
        "    info = item_information(theta_range, b=b)\n",
        "    ax.plot(theta_range, info, label=f'b = {b}', color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Information Functions by Difficulty (1PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Item Information', fontsize=12)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Information functions for different discriminations\n",
        "ax = axes[0, 1]\n",
        "discrimination_levels = [0.5, 1.0, 1.5, 2.0]\n",
        "colors = plt.cm.plasma(np.linspace(0, 1, len(discrimination_levels)))\n",
        "\n",
        "for i, a in enumerate(discrimination_levels):\n",
        "    info = item_information(theta_range, b=0, a=a)\n",
        "    ax.plot(theta_range, info, label=f'a = {a}', color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Information Functions by Discrimination (2PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Item Information', fontsize=12)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Information functions for different guessing parameters\n",
        "ax = axes[1, 0]\n",
        "guessing_levels = [0.0, 0.1, 0.2, 0.25]\n",
        "colors = plt.cm.inferno(np.linspace(0, 1, len(guessing_levels)))\n",
        "\n",
        "for i, c in enumerate(guessing_levels):\n",
        "    info = item_information(theta_range, b=0, a=1, c=c)\n",
        "    ax.plot(theta_range, info, label=f'c = {c}', color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Information Functions by Guessing (3PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Item Information', fontsize=12)\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Combined information functions\n",
        "ax = axes[1, 1]\n",
        "item_configs = [\n",
        "    {'b': -1, 'a': 1.5, 'c': 0.0, 'label': 'Easy, High Discrim., No Guess'},\n",
        "    {'b': 0, 'a': 1.0, 'c': 0.1, 'label': 'Medium, Med Discrim., Low Guess'},\n",
        "    {'b': 1, 'a': 0.8, 'c': 0.2, 'label': 'Hard, Low Discrim., High Guess'},\n",
        "    {'b': 0, 'a': 2.0, 'c': 0.05, 'label': 'Medium, Very High Discrim., Low Guess'}\n",
        "]\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(item_configs)))\n",
        "\n",
        "for i, config in enumerate(item_configs):\n",
        "    info = item_information(theta_range, b=config['b'], a=config['a'], c=config['c'])\n",
        "    ax.plot(theta_range, info, label=config['label'], color=colors[i], linewidth=2)\n",
        "\n",
        "ax.set_title('Combined Information Functions (3PL Model)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Ability (θ)', fontsize=12)\n",
        "ax.set_ylabel('Item Information', fontsize=12)\n",
        "ax.legend(fontsize=9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Information functions generated successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Adaptive Testing Simulation\n",
        "\n",
        "Now let's simulate an adaptive test where we select the most informative items based on the current ability estimate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_adaptive_test(true_ability=1.2, max_items=10, n_items_pool=20):\n",
        "    \"\"\"\n",
        "    Simulate a simple adaptive test for a student.\n",
        "\n",
        "    This demonstrates the basic principle of adaptive testing:\n",
        "    1. Start with an initial ability estimate\n",
        "    2. Select the most informative item\n",
        "    3. Administer the item and get response\n",
        "    4. Update ability estimate\n",
        "    5. Repeat until stopping criterion is met\n",
        "    \"\"\"\n",
        "    # Create a pool of items with known parameters\n",
        "    item_pool = pd.DataFrame({\n",
        "        'item_id': range(1, n_items_pool + 1),\n",
        "        'b': np.linspace(-3, 3, n_items_pool),  # Difficulties from -3 to 3\n",
        "        'a': np.random.uniform(0.7, 1.8, n_items_pool),  # Discriminations\n",
        "        'c': np.random.uniform(0.0, 0.25, n_items_pool)   # Guessing parameters\n",
        "    })\n",
        "\n",
        "    # Initialize test\n",
        "    current_estimate = 0.0  # Initial ability estimate (middle of scale)\n",
        "    administered_items = []\n",
        "    responses = []\n",
        "    ability_estimates = [current_estimate]\n",
        "    information_history = []\n",
        "\n",
        "    # Run adaptive algorithm\n",
        "    for i in range(max_items):\n",
        "        # Find available items (not yet administered)\n",
        "        available_items = item_pool[~item_pool['item_id'].isin(administered_items)].copy()\n",
        "\n",
        "        # Calculate information for all available items at current ability estimate\n",
        "        available_items['info'] = available_items.apply(\n",
        "            lambda row: item_information(current_estimate, row['b'], row['a'], row['c']), \n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Select most informative item\n",
        "        next_item = available_items.loc[available_items['info'].idxmax()]\n",
        "        max_info = next_item['info']\n",
        "\n",
        "        # Simulate response\n",
        "        response = simulate_response(\n",
        "            true_ability,\n",
        "            next_item['b'],\n",
        "            next_item['a'],\n",
        "            next_item['c']\n",
        "        )\n",
        "\n",
        "        # Update administered items and responses\n",
        "        administered_items.append(next_item['item_id'])\n",
        "        responses.append(response)\n",
        "        information_history.append(max_info)\n",
        "\n",
        "        # Update ability estimate (simplified - in practice would use MLE or Bayesian methods)\n",
        "        # This is a simplified estimate update using response pattern\n",
        "        if response == 1:  # Correct\n",
        "            current_estimate = current_estimate + (1 - irt_probability(\n",
        "                current_estimate, next_item['b'], next_item['a'], next_item['c']\n",
        "            )) * 0.5\n",
        "        else:  # Incorrect\n",
        "            current_estimate = current_estimate - irt_probability(\n",
        "                current_estimate, next_item['b'], next_item['a'], next_item['c']\n",
        "            ) * 0.5\n",
        "\n",
        "        ability_estimates.append(current_estimate)\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'item_number': range(1, max_items + 1),\n",
        "        'item_id': administered_items,\n",
        "        'difficulty': [item_pool.loc[item_pool['item_id'] == item_id, 'b'].values[0] \n",
        "                      for item_id in administered_items],\n",
        "        'discrimination': [item_pool.loc[item_pool['item_id'] == item_id, 'a'].values[0] \n",
        "                          for item_id in administered_items],\n",
        "        'guessing': [item_pool.loc[item_pool['item_id'] == item_id, 'c'].values[0] \n",
        "                    for item_id in administered_items],\n",
        "        'response': responses,\n",
        "        'information': information_history\n",
        "    })\n",
        "\n",
        "    return results, ability_estimates, true_ability\n",
        "\n",
        "print(\"Adaptive testing function defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run adaptive test simulation\n",
        "print(\"Running adaptive test simulation...\")\n",
        "results, ability_estimates, true_ability = simulate_adaptive_test(\n",
        "    true_ability=1.2, max_items=10, n_items_pool=20\n",
        ")\n",
        "\n",
        "print(\"Adaptive Test Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(results)\n",
        "\n",
        "print(f\"\\nTrue ability: {true_ability:.2f}\")\n",
        "print(f\"Final estimate: {ability_estimates[-1]:.2f}\")\n",
        "print(f\"Estimation error: {abs(true_ability - ability_estimates[-1]):.2f}\")\n",
        "print(f\"Total score: {sum(results['response'])}/{len(results)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Visualize Adaptive Testing Results\n",
        "\n",
        "Let's create comprehensive visualizations of our adaptive testing simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive adaptive testing visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Ability estimate convergence\n",
        "ax = axes[0, 0]\n",
        "item_numbers = range(len(ability_estimates))\n",
        "ax.plot(item_numbers, ability_estimates, 'bo-', linewidth=2, markersize=8, label='Ability Estimate')\n",
        "ax.axhline(y=true_ability, color='r', linestyle='--', linewidth=2, label=f'True Ability = {true_ability}')\n",
        "ax.set_xlabel('Number of Items Administered')\n",
        "ax.set_ylabel('Ability Estimate (θ)')\n",
        "ax.set_title('Adaptive Testing: Ability Estimate Convergence', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Information values over time\n",
        "ax = axes[0, 1]\n",
        "ax.plot(results['item_number'], results['information'], 'go-', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Item Number')\n",
        "ax.set_ylabel('Item Information')\n",
        "ax.set_title('Information Values of Selected Items', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Item difficulty progression\n",
        "ax = axes[1, 0]\n",
        "colors = ['green' if r == 1 else 'red' for r in results['response']]\n",
        "ax.scatter(results['item_number'], results['difficulty'], c=colors, s=100, alpha=0.7)\n",
        "ax.axhline(y=true_ability, color='blue', linestyle='--', linewidth=2, label=f'True Ability = {true_ability}')\n",
        "ax.set_xlabel('Item Number')\n",
        "ax.set_ylabel('Item Difficulty (b)')\n",
        "ax.set_title('Item Difficulty vs. True Ability', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Response pattern\n",
        "ax = axes[1, 1]\n",
        "response_counts = results['response'].value_counts()\n",
        "labels = ['Incorrect', 'Correct']\n",
        "colors = ['red', 'green']\n",
        "ax.pie(response_counts.values, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "ax.set_title('Response Pattern Distribution', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Adaptive testing visualizations completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Multiple Student Simulation\n",
        "\n",
        "Let's simulate adaptive tests for multiple students with different ability levels to see how the algorithm performs across the ability spectrum.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate adaptive tests for multiple students\n",
        "student_abilities = [-2, -1, 0, 1, 2]  # Different ability levels\n",
        "all_results = []\n",
        "\n",
        "print(\"Simulating adaptive tests for multiple students...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, true_ability in enumerate(student_abilities):\n",
        "    print(f\"\\nStudent {i+1} - True Ability: {true_ability}\")\n",
        "    results, ability_estimates, _ = simulate_adaptive_test(\n",
        "        true_ability=true_ability, max_items=8, n_items_pool=20\n",
        "    )\n",
        "    \n",
        "    final_estimate = ability_estimates[-1]\n",
        "    estimation_error = abs(true_ability - final_estimate)\n",
        "    score = sum(results['response'])\n",
        "    \n",
        "    print(f\"  Final estimate: {final_estimate:.2f}\")\n",
        "    print(f\"  Estimation error: {estimation_error:.2f}\")\n",
        "    print(f\"  Score: {score}/{len(results)}\")\n",
        "    \n",
        "    # Store results for analysis\n",
        "    all_results.append({\n",
        "        'student_id': i+1,\n",
        "        'true_ability': true_ability,\n",
        "        'final_estimate': final_estimate,\n",
        "        'estimation_error': estimation_error,\n",
        "        'score': score,\n",
        "        'total_items': len(results)\n",
        "    })\n",
        "\n",
        "# Create summary DataFrame\n",
        "summary_df = pd.DataFrame(all_results)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY OF ALL STUDENTS\")\n",
        "print(\"=\" * 60)\n",
        "print(summary_df)\n",
        "\n",
        "print(f\"\\nOverall Performance:\")\n",
        "print(f\"- Average estimation error: {summary_df['estimation_error'].mean():.3f}\")\n",
        "print(f\"- Standard deviation of errors: {summary_df['estimation_error'].std():.3f}\")\n",
        "print(f\"- Average score: {summary_df['score'].mean():.1f}/{summary_df['total_items'].iloc[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Save Results and Visualizations\n",
        "\n",
        "Let's save our simulation results and create final visualizations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final summary visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# 1. Estimation accuracy across ability levels\n",
        "ax = axes[0]\n",
        "ax.scatter(summary_df['true_ability'], summary_df['estimation_error'], \n",
        "          s=100, c='red', alpha=0.7, edgecolors='black')\n",
        "ax.plot(summary_df['true_ability'], summary_df['estimation_error'], \n",
        "        'r--', alpha=0.5)\n",
        "ax.set_xlabel('True Ability (θ)')\n",
        "ax.set_ylabel('Estimation Error')\n",
        "ax.set_title('Estimation Accuracy Across Ability Levels', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Score distribution\n",
        "ax = axes[1]\n",
        "ax.bar(summary_df['student_id'], summary_df['score'], \n",
        "       color='skyblue', alpha=0.7, edgecolor='black')\n",
        "ax.set_xlabel('Student ID')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Score Distribution Across Students', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(summary_df['student_id'])\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save results to files\n",
        "results_dir = \"../data\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Save summary results\n",
        "summary_df.to_csv(os.path.join(results_dir, \"adaptive_testing_summary.csv\"), index=False)\n",
        "print(f\"\\nResults saved to: {results_dir}/adaptive_testing_summary.csv\")\n",
        "\n",
        "print(\"\\nSimulation analysis completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Summary and Key Insights\n",
        "\n",
        "## What We've Accomplished\n",
        "\n",
        "1. **IRT Function Analysis**: Explored how different parameters affect probability and information functions\n",
        "2. **Item Characteristic Curves**: Visualized how items behave across ability levels\n",
        "3. **Information Functions**: Understood how items provide information at different ability levels\n",
        "4. **Adaptive Testing**: Simulated intelligent test administration\n",
        "5. **Multi-Student Analysis**: Evaluated performance across different ability levels\n",
        "\n",
        "## Key Insights\n",
        "\n",
        "### Parameter Effects:\n",
        "- **Difficulty (b)**: Shifts the curve left/right along the ability axis\n",
        "- **Discrimination (a)**: Controls the steepness of the curve\n",
        "- **Guessing (c)**: Sets the lower bound of the probability\n",
        "\n",
        "### Adaptive Testing Benefits:\n",
        "- **Efficient**: Selects most informative items\n",
        "- **Precise**: Converges to true ability estimate\n",
        "- **Personalized**: Adapts to individual student level\n",
        "\n",
        "### Performance Metrics:\n",
        "- Estimation accuracy varies by ability level\n",
        "- Information-based selection improves precision\n",
        "- Adaptive algorithms reduce test length while maintaining accuracy\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "This simulation provides a foundation for:\n",
        "- **Real adaptive testing systems**\n",
        "- **IRT model parameter estimation**\n",
        "- **Educational assessment optimization**\n",
        "- **Psychometric research applications**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
