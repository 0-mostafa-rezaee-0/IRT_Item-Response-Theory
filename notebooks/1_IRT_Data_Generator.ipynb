{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "<h1>IRT Data Generator</h1>\n",
        "</div>\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to generate synthetic Item Response Theory (IRT) data for educational and research purposes. The notebook covers:\n",
        "\n",
        "1. **Understanding IRT Models**: 1PL, 2PL, and 3PL models\n",
        "2. **Data Generation Process**: Creating realistic student abilities and item parameters\n",
        "3. **Response Simulation**: Generating binary responses based on IRT probabilities\n",
        "4. **Data Export**: Saving generated data for further analysis\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- How IRT models work mathematically\n",
        "- How to generate realistic educational data\n",
        "- The differences between 1PL, 2PL, and 3PL models\n",
        "- How to create datasets suitable for IRT analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import Required Libraries\n",
        "\n",
        "First, let's import all the necessary libraries for our IRT data generation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Understanding IRT Models\n",
        "\n",
        "## What is Item Response Theory?\n",
        "\n",
        "Item Response Theory (IRT) is a psychometric framework for designing, analyzing, and scoring tests, questionnaires, and other instruments that measure abilities, attitudes, or other variables.\n",
        "\n",
        "### Key IRT Models:\n",
        "\n",
        "1. **1PL (Rasch Model)**: Only difficulty parameter (b)\n",
        "2. **2PL Model**: Difficulty (b) + discrimination (a) parameters  \n",
        "3. **3PL Model**: Difficulty (b) + discrimination (a) + guessing (c) parameters\n",
        "\n",
        "### The 3PL Model Formula:\n",
        "\n",
        "**P(correct) = c + (1-c) / (1 + exp(-a(θ-b)))**\n",
        "\n",
        "Where:\n",
        "- **θ (theta)**: Student ability\n",
        "- **b**: Item difficulty  \n",
        "- **a**: Item discrimination\n",
        "- **c**: Guessing parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. IRT Data Generation Function\n",
        "\n",
        "Let's create a comprehensive function to generate IRT data with different model specifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_irt_data(n_students=500, n_items=20, model=\"3PL\", seed=42):\n",
        "    \"\"\"\n",
        "    Generate synthetic IRT data based on specified model.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_students : int\n",
        "        Number of students to simulate\n",
        "    n_items : int\n",
        "        Number of items to simulate\n",
        "    model : str\n",
        "        IRT model to use ('1PL', '2PL', or '3PL')\n",
        "    seed : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    responses_df : pandas DataFrame\n",
        "        Matrix of student responses (1=correct, 0=incorrect)\n",
        "    parameters_df : pandas DataFrame\n",
        "        Item parameters for the generated items\n",
        "    abilities : numpy array\n",
        "        Generated ability parameters for students\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Generate student abilities from N(0, 1)\n",
        "    abilities = np.random.normal(0, 1, size=n_students)\n",
        "\n",
        "    # Generate item parameters\n",
        "    difficulties = np.random.uniform(-3, 3, size=n_items)  # b parameters\n",
        "\n",
        "    if model in [\"2PL\", \"3PL\"]:\n",
        "        discriminations = np.random.uniform(0.5, 2.0, size=n_items)  # a parameters\n",
        "    else:\n",
        "        discriminations = np.ones(n_items)  # For 1PL, all discriminations = 1\n",
        "\n",
        "    if model == \"3PL\":\n",
        "        guessing = np.random.uniform(0.05, 0.25, size=n_items)  # c parameters\n",
        "    else:\n",
        "        guessing = np.zeros(n_items)  # For 1PL/2PL, no guessing\n",
        "\n",
        "    # Generate response probabilities using the IRT model\n",
        "    responses = np.zeros((n_students, n_items))\n",
        "    for i in range(n_students):\n",
        "        for j in range(n_items):\n",
        "            theta = abilities[i]\n",
        "            a = discriminations[j]\n",
        "            b = difficulties[j]\n",
        "            c = guessing[j]\n",
        "\n",
        "            # 3PL model formula: P(correct) = c + (1-c) / (1 + exp(-a(theta-b)))\n",
        "            p = c + (1 - c) / (1 + np.exp(-a * (theta - b)))\n",
        "            responses[i, j] = np.random.binomial(1, p)\n",
        "\n",
        "    # Create DataFrames\n",
        "    responses_df = pd.DataFrame(\n",
        "        responses,\n",
        "        columns=[f\"item_{j+1}\" for j in range(n_items)]\n",
        "    )\n",
        "    responses_df.insert(0, \"student_id\", range(1, n_students + 1))\n",
        "\n",
        "    parameters_df = pd.DataFrame({\n",
        "        \"item_id\": [f\"item_{j+1}\" for j in range(n_items)],\n",
        "        \"difficulty\": difficulties,\n",
        "        \"discrimination\": discriminations,\n",
        "        \"guessing\": guessing\n",
        "    })\n",
        "\n",
        "    return responses_df, parameters_df, abilities\n",
        "\n",
        "print(\"IRT data generation function created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Generate Sample Data\n",
        "\n",
        "Let's generate sample data using different IRT models to see how they compare.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate data using different models\n",
        "print(\"Generating IRT data with different models...\")\n",
        "\n",
        "# 1PL Model (Rasch)\n",
        "responses_1pl, params_1pl, abilities_1pl = generate_irt_data(\n",
        "    n_students=200, n_items=10, model=\"1PL\", seed=42\n",
        ")\n",
        "\n",
        "# 2PL Model\n",
        "responses_2pl, params_2pl, abilities_2pl = generate_irt_data(\n",
        "    n_students=200, n_items=10, model=\"2PL\", seed=42\n",
        ")\n",
        "\n",
        "# 3PL Model\n",
        "responses_3pl, params_3pl, abilities_3pl = generate_irt_data(\n",
        "    n_students=200, n_items=10, model=\"3PL\", seed=42\n",
        ")\n",
        "\n",
        "print(\"Data generation completed!\")\n",
        "print(f\"1PL Model - Students: {len(responses_1pl)}, Items: {len(params_1pl)}\")\n",
        "print(f\"2PL Model - Students: {len(responses_2pl)}, Items: {len(params_2pl)}\")\n",
        "print(f\"3PL Model - Students: {len(responses_3pl)}, Items: {len(params_3pl)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Explore Generated Data\n",
        "\n",
        "Let's examine the structure and characteristics of our generated data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine 3PL model data (most comprehensive)\n",
        "print(\"=== 3PL Model Data Overview ===\")\n",
        "print(\"\\nResponse Matrix (first 5 students):\")\n",
        "print(responses_3pl.head())\n",
        "\n",
        "print(\"\\nItem Parameters:\")\n",
        "print(params_3pl)\n",
        "\n",
        "print(\"\\nStudent Abilities (first 10):\")\n",
        "print(abilities_3pl[:10])\n",
        "\n",
        "print(f\"\\nData Summary:\")\n",
        "print(f\"- Total students: {len(responses_3pl)}\")\n",
        "print(f\"- Total items: {len(params_3pl)}\")\n",
        "print(f\"- Average score: {responses_3pl.iloc[:, 1:].mean().mean():.3f}\")\n",
        "print(f\"- Score range: {responses_3pl.iloc[:, 1:].sum(axis=1).min()} - {responses_3pl.iloc[:, 1:].sum(axis=1).max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Visualize Data Characteristics\n",
        "\n",
        "Let's create visualizations to better understand our generated data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Student ability distribution\n",
        "axes[0, 0].hist(abilities_3pl, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Distribution of Student Abilities (θ)')\n",
        "axes[0, 0].set_xlabel('Ability (θ)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Item difficulty distribution\n",
        "axes[0, 1].hist(params_3pl['difficulty'], bins=15, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[0, 1].set_title('Distribution of Item Difficulties (b)')\n",
        "axes[0, 1].set_xlabel('Difficulty (b)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Item discrimination distribution\n",
        "axes[1, 0].hist(params_3pl['discrimination'], bins=15, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[1, 0].set_title('Distribution of Item Discriminations (a)')\n",
        "axes[1, 0].set_xlabel('Discrimination (a)')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Item guessing distribution\n",
        "axes[1, 1].hist(params_3pl['guessing'], bins=15, alpha=0.7, color='gold', edgecolor='black')\n",
        "axes[1, 1].set_title('Distribution of Item Guessing Parameters (c)')\n",
        "axes[1, 1].set_xlabel('Guessing (c)')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Compare Different IRT Models\n",
        "\n",
        "Let's compare the characteristics of data generated by different IRT models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare model characteristics\n",
        "print(\"=== Model Comparison ===\")\n",
        "print(\"\\nItem Parameters Comparison:\")\n",
        "print(\"\\n1PL Model (Rasch):\")\n",
        "print(f\"- All discriminations = 1.0\")\n",
        "print(f\"- No guessing parameters\")\n",
        "print(f\"- Difficulty range: {params_1pl['difficulty'].min():.2f} to {params_1pl['difficulty'].max():.2f}\")\n",
        "\n",
        "print(\"\\n2PL Model:\")\n",
        "print(f\"- Discrimination range: {params_2pl['discrimination'].min():.2f} to {params_2pl['discrimination'].max():.2f}\")\n",
        "print(f\"- No guessing parameters\")\n",
        "print(f\"- Difficulty range: {params_2pl['difficulty'].min():.2f} to {params_2pl['difficulty'].max():.2f}\")\n",
        "\n",
        "print(\"\\n3PL Model:\")\n",
        "print(f\"- Discrimination range: {params_3pl['discrimination'].min():.2f} to {params_3pl['discrimination'].max():.2f}\")\n",
        "print(f\"- Guessing range: {params_3pl['guessing'].min():.3f} to {params_3pl['guessing'].max():.3f}\")\n",
        "print(f\"- Difficulty range: {params_3pl['difficulty'].min():.2f} to {params_3pl['difficulty'].max():.2f}\")\n",
        "\n",
        "# Compare response patterns\n",
        "print(\"\\n=== Response Pattern Comparison ===\")\n",
        "for model_name, responses in [(\"1PL\", responses_1pl), (\"2PL\", responses_2pl), (\"3PL\", responses_3pl)]:\n",
        "    avg_score = responses.iloc[:, 1:].mean().mean()\n",
        "    score_std = responses.iloc[:, 1:].sum(axis=1).std()\n",
        "    print(f\"{model_name} Model - Average probability: {avg_score:.3f}, Score std: {score_std:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Save Generated Data\n",
        "\n",
        "Now let's save our generated data to files for further analysis or use in other notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data directory if it doesn't exist\n",
        "data_dir = \"../data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Save 3PL model data (most comprehensive)\n",
        "print(\"Saving generated data...\")\n",
        "\n",
        "# Save response matrices\n",
        "responses_3pl.to_csv(os.path.join(data_dir, \"irt_responses_3pl.csv\"), index=False)\n",
        "responses_2pl.to_csv(os.path.join(data_dir, \"irt_responses_2pl.csv\"), index=False)\n",
        "responses_1pl.to_csv(os.path.join(data_dir, \"irt_responses_1pl.csv\"), index=False)\n",
        "\n",
        "# Save parameter matrices\n",
        "params_3pl.to_csv(os.path.join(data_dir, \"irt_parameters_3pl.csv\"), index=False)\n",
        "params_2pl.to_csv(os.path.join(data_dir, \"irt_parameters_2pl.csv\"), index=False)\n",
        "params_1pl.to_csv(os.path.join(data_dir, \"irt_parameters_1pl.csv\"), index=False)\n",
        "\n",
        "# Save ability arrays\n",
        "np.save(os.path.join(data_dir, \"student_abilities_3pl.npy\"), abilities_3pl)\n",
        "np.save(os.path.join(data_dir, \"student_abilities_2pl.npy\"), abilities_2pl)\n",
        "np.save(os.path.join(data_dir, \"student_abilities_1pl.npy\"), abilities_1pl)\n",
        "\n",
        "print(\"Data saved successfully!\")\n",
        "print(f\"Files saved to: {data_dir}\")\n",
        "print(\"\\nSaved files:\")\n",
        "print(\"- irt_responses_1pl.csv, irt_responses_2pl.csv, irt_responses_3pl.csv\")\n",
        "print(\"- irt_parameters_1pl.csv, irt_parameters_2pl.csv, irt_parameters_3pl.csv\")\n",
        "print(\"- student_abilities_1pl.npy, student_abilities_2pl.npy, student_abilities_3pl.npy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Summary and Next Steps\n",
        "\n",
        "## What We've Accomplished\n",
        "\n",
        "1. **Generated synthetic IRT data** using three different models (1PL, 2PL, 3PL)\n",
        "2. **Explored data characteristics** through visualizations and statistics\n",
        "3. **Compared model differences** in terms of parameters and response patterns\n",
        "4. **Saved data files** for further analysis\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "- **1PL (Rasch) Model**: Simplest model with only difficulty parameters\n",
        "- **2PL Model**: Adds discrimination parameters for varying item quality\n",
        "- **3PL Model**: Most comprehensive with difficulty, discrimination, and guessing parameters\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "You can now use this generated data for:\n",
        "- **IRT model fitting** and parameter estimation\n",
        "- **Adaptive testing simulations**\n",
        "- **Educational assessment research**\n",
        "- **Psychometric analysis**\n",
        "\n",
        "## Files Generated\n",
        "\n",
        "- Response matrices for each model\n",
        "- Item parameter files\n",
        "- Student ability arrays\n",
        "- All saved in the `../data/` directory\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
