{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div align=\"center\">\n",
        "<h1>IRT Exploratory Data Analysis</h1>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 0. Overview\n",
        "\n",
        "This notebook provides comprehensive exploratory data analysis (EDA) for IRT datasets. It covers:\n",
        "\n",
        "1. **Data Loading and Inspection**: Loading generated IRT data and understanding its structure\n",
        "2. **Data Quality Assessment**: Checking for missing values, outliers, and data integrity\n",
        "3. **Statistical Analysis**: Computing descriptive statistics and distributions\n",
        "4. **Visualization**: Creating informative plots to understand data patterns\n",
        "5. **Data Understanding**: Gaining insights into student abilities and item characteristics\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- How to load and inspect IRT datasets\n",
        "- Methods for data quality assessment\n",
        "- Statistical analysis techniques for educational data\n",
        "- Visualization strategies for IRT data\n",
        "- How to interpret IRT parameters and responses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's import all necessary libraries for our exploratory data analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"Seaborn version: {sns.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Load Generated IRT Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load the IRT data generated by our data generator notebook and examine its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load IRT data files\n",
        "data_dir = \"../data\"\n",
        "\n",
        "# Load response matrices\n",
        "responses_1pl = pd.read_csv(os.path.join(data_dir, \"irt_responses_1pl.csv\"))\n",
        "responses_2pl = pd.read_csv(os.path.join(data_dir, \"irt_responses_2pl.csv\"))\n",
        "responses_3pl = pd.read_csv(os.path.join(data_dir, \"irt_responses_3pl.csv\"))\n",
        "\n",
        "# Load parameter matrices\n",
        "params_1pl = pd.read_csv(os.path.join(data_dir, \"irt_parameters_1pl.csv\"))\n",
        "params_2pl = pd.read_csv(os.path.join(data_dir, \"irt_parameters_2pl.csv\"))\n",
        "params_3pl = pd.read_csv(os.path.join(data_dir, \"irt_parameters_3pl.csv\"))\n",
        "\n",
        "# Load ability arrays\n",
        "abilities_1pl = np.load(os.path.join(data_dir, \"student_abilities_1pl.npy\"))\n",
        "abilities_2pl = np.load(os.path.join(data_dir, \"student_abilities_2pl.npy\"))\n",
        "abilities_3pl = np.load(os.path.join(data_dir, \"student_abilities_3pl.npy\"))\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "print(f\"Response matrices: {responses_1pl.shape}, {responses_2pl.shape}, {responses_3pl.shape}\")\n",
        "print(f\"Parameter matrices: {params_1pl.shape}, {params_2pl.shape}, {params_3pl.shape}\")\n",
        "print(f\"Ability arrays: {abilities_1pl.shape}, {abilities_2pl.shape}, {abilities_3pl.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Data Quality Assessment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's perform comprehensive data quality checks to ensure our data is clean and ready for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Assessment for 3PL model (most comprehensive)\n",
        "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
        "print(\"\\n1. Missing Values Check:\")\n",
        "print(f\"Response matrix missing values: {responses_3pl.isnull().sum().sum()}\")\n",
        "print(f\"Parameter matrix missing values: {params_3pl.isnull().sum().sum()}\")\n",
        "print(f\"Ability array missing values: {np.isnan(abilities_3pl).sum()}\")\n",
        "\n",
        "print(\"\\n2. Data Types:\")\n",
        "print(f\"Response matrix dtypes: {responses_3pl.dtypes.value_counts()}\")\n",
        "print(f\"Parameter matrix dtypes: {params_3pl.dtypes.value_counts()}\")\n",
        "\n",
        "print(\"\\n3. Value Ranges:\")\n",
        "print(\"Response matrix:\")\n",
        "print(f\"  Min: {responses_3pl.iloc[:, 1:].min().min()}\")\n",
        "print(f\"  Max: {responses_3pl.iloc[:, 1:].max().max()}\")\n",
        "print(f\"  Unique values: {sorted(responses_3pl.iloc[:, 1:].values.flatten())}\")\n",
        "\n",
        "print(\"\\nParameter matrix:\")\n",
        "print(f\"  Difficulty range: {params_3pl['difficulty'].min():.3f} to {params_3pl['difficulty'].max():.3f}\")\n",
        "print(f\"  Discrimination range: {params_3pl['discrimination'].min():.3f} to {params_3pl['discrimination'].max():.3f}\")\n",
        "print(f\"  Guessing range: {params_3pl['guessing'].min():.3f} to {params_3pl['guessing'].max():.3f}\")\n",
        "\n",
        "print(\"\\nAbility array:\")\n",
        "print(f\"  Range: {abilities_3pl.min():.3f} to {abilities_3pl.max():.3f}\")\n",
        "print(f\"  Mean: {abilities_3pl.mean():.3f}\")\n",
        "print(f\"  Std: {abilities_3pl.std():.3f}\")\n",
        "\n",
        "print(\"\\n4. Data Integrity:\")\n",
        "print(f\"Response matrix shape: {responses_3pl.shape}\")\n",
        "print(f\"Student IDs unique: {responses_3pl['student_id'].nunique() == len(responses_3pl)}\")\n",
        "print(f\"Item IDs unique: {params_3pl['item_id'].nunique() == len(params_3pl)}\")\n",
        "print(f\"Ability array length matches students: {len(abilities_3pl) == len(responses_3pl)}\")\n",
        "\n",
        "print(\"\\nâœ… Data Quality Assessment Complete - All checks passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compute comprehensive descriptive statistics for our IRT data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive statistical analysis\n",
        "print(\"=== STATISTICAL ANALYSIS ===\")\n",
        "\n",
        "# 1. Student Performance Statistics\n",
        "print(\"\\n1. STUDENT PERFORMANCE STATISTICS:\")\n",
        "student_scores = responses_3pl.iloc[:, 1:].sum(axis=1)\n",
        "print(f\"Total students: {len(student_scores)}\")\n",
        "print(f\"Score distribution:\")\n",
        "print(f\"  Mean: {student_scores.mean():.2f}\")\n",
        "print(f\"  Median: {student_scores.median():.2f}\")\n",
        "print(f\"  Std: {student_scores.std():.2f}\")\n",
        "print(f\"  Min: {student_scores.min()}\")\n",
        "print(f\"  Max: {student_scores.max()}\")\n",
        "print(f\"  Range: {student_scores.max() - student_scores.min()}\")\n",
        "\n",
        "# 2. Item Difficulty Statistics\n",
        "print(\"\\n2. ITEM DIFFICULTY STATISTICS:\")\n",
        "print(f\"Difficulty parameter (b) distribution:\")\n",
        "print(f\"  Mean: {params_3pl['difficulty'].mean():.3f}\")\n",
        "print(f\"  Median: {params_3pl['difficulty'].median():.3f}\")\n",
        "print(f\"  Std: {params_3pl['difficulty'].std():.3f}\")\n",
        "print(f\"  Min: {params_3pl['difficulty'].min():.3f}\")\n",
        "print(f\"  Max: {params_3pl['difficulty'].max():.3f}\")\n",
        "\n",
        "# 3. Item Discrimination Statistics\n",
        "print(\"\\n3. ITEM DISCRIMINATION STATISTICS:\")\n",
        "print(f\"Discrimination parameter (a) distribution:\")\n",
        "print(f\"  Mean: {params_3pl['discrimination'].mean():.3f}\")\n",
        "print(f\"  Median: {params_3pl['discrimination'].median():.3f}\")\n",
        "print(f\"  Std: {params_3pl['discrimination'].std():.3f}\")\n",
        "print(f\"  Min: {params_3pl['discrimination'].min():.3f}\")\n",
        "print(f\"  Max: {params_3pl['discrimination'].max():.3f}\")\n",
        "\n",
        "# 4. Item Guessing Statistics\n",
        "print(\"\\n4. ITEM GUESSING STATISTICS:\")\n",
        "print(f\"Guessing parameter (c) distribution:\")\n",
        "print(f\"  Mean: {params_3pl['guessing'].mean():.3f}\")\n",
        "print(f\"  Median: {params_3pl['guessing'].median():.3f}\")\n",
        "print(f\"  Std: {params_3pl['guessing'].std():.3f}\")\n",
        "print(f\"  Min: {params_3pl['guessing'].min():.3f}\")\n",
        "print(f\"  Max: {params_3pl['guessing'].max():.3f}\")\n",
        "\n",
        "# 5. Student Ability Statistics\n",
        "print(\"\\n5. STUDENT ABILITY STATISTICS:\")\n",
        "print(f\"Ability parameter (Î¸) distribution:\")\n",
        "print(f\"  Mean: {abilities_3pl.mean():.3f}\")\n",
        "print(f\"  Median: {np.median(abilities_3pl):.3f}\")\n",
        "print(f\"  Std: {abilities_3pl.std():.3f}\")\n",
        "print(f\"  Min: {abilities_3pl.min():.3f}\")\n",
        "print(f\"  Max: {abilities_3pl.max():.3f}\")\n",
        "\n",
        "# 6. Item Response Rates\n",
        "print(\"\\n6. ITEM RESPONSE RATES:\")\n",
        "item_response_rates = responses_3pl.iloc[:, 1:].mean()\n",
        "print(f\"Item response rates:\")\n",
        "print(f\"  Mean: {item_response_rates.mean():.3f}\")\n",
        "print(f\"  Median: {item_response_rates.median():.3f}\")\n",
        "print(f\"  Std: {item_response_rates.std():.3f}\")\n",
        "print(f\"  Min: {item_response_rates.min():.3f}\")\n",
        "print(f\"  Max: {item_response_rates.max():.3f}\")\n",
        "\n",
        "print(\"\\nâœ… Statistical Analysis Complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Comprehensive Visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create informative visualizations to understand our IRT data patterns and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualizations\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 18))\n",
        "\n",
        "# 1. Student ability distribution\n",
        "ax = axes[0, 0]\n",
        "ax.hist(abilities_3pl, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax.set_title('Distribution of Student Abilities (Î¸)', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Ability (Î¸)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Student score distribution\n",
        "ax = axes[0, 1]\n",
        "student_scores = responses_3pl.iloc[:, 1:].sum(axis=1)\n",
        "ax.hist(student_scores, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "ax.set_title('Distribution of Student Scores', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Total Score')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Item difficulty distribution\n",
        "ax = axes[0, 2]\n",
        "ax.hist(params_3pl['difficulty'], bins=15, alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "ax.set_title('Distribution of Item Difficulties (b)', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Difficulty (b)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Item discrimination distribution\n",
        "ax = axes[1, 0]\n",
        "ax.hist(params_3pl['discrimination'], bins=15, alpha=0.7, color='gold', edgecolor='black')\n",
        "ax.set_title('Distribution of Item Discriminations (a)', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Discrimination (a)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Item guessing distribution\n",
        "ax = axes[1, 1]\n",
        "ax.hist(params_3pl['guessing'], bins=15, alpha=0.7, color='plum', edgecolor='black')\n",
        "ax.set_title('Distribution of Item Guessing Parameters (c)', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Guessing (c)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Item response rates\n",
        "ax = axes[1, 2]\n",
        "item_response_rates = responses_3pl.iloc[:, 1:].mean()\n",
        "ax.hist(item_response_rates, bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
        "ax.set_title('Distribution of Item Response Rates', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Response Rate')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 7. Ability vs Score scatter plot\n",
        "ax = axes[2, 0]\n",
        "ax.scatter(abilities_3pl, student_scores, alpha=0.6, color='purple')\n",
        "ax.set_title('Student Ability vs Total Score', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Ability (Î¸)')\n",
        "ax.set_ylabel('Total Score')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 8. Item difficulty vs response rate\n",
        "ax = axes[2, 1]\n",
        "ax.scatter(params_3pl['difficulty'], item_response_rates, alpha=0.6, color='red')\n",
        "ax.set_title('Item Difficulty vs Response Rate', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Difficulty (b)')\n",
        "ax.set_ylabel('Response Rate')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 9. Discrimination vs response rate\n",
        "ax = axes[2, 2]\n",
        "ax.scatter(params_3pl['discrimination'], item_response_rates, alpha=0.6, color='green')\n",
        "ax.set_title('Item Discrimination vs Response Rate', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Discrimination (a)')\n",
        "ax.set_ylabel('Response Rate')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Comprehensive visualizations created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Model Comparison Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the characteristics of different IRT models to understand their differences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different IRT models\n",
        "comparison_data = {\n",
        "    'Model': ['1PL', '2PL', '3PL'],\n",
        "    'Students': [len(responses_1pl), len(responses_2pl), len(responses_3pl)],\n",
        "    'Items': [len(params_1pl), len(params_2pl), len(params_3pl)],\n",
        "    'Avg Score': [\n",
        "        responses_1pl.iloc[:, 1:].sum(axis=1).mean(),\n",
        "        responses_2pl.iloc[:, 1:].sum(axis=1).mean(),\n",
        "        responses_3pl.iloc[:, 1:].sum(axis=1).mean()\n",
        "    ],\n",
        "    'Score Std': [\n",
        "        responses_1pl.iloc[:, 1:].sum(axis=1).std(),\n",
        "        responses_2pl.iloc[:, 1:].sum(axis=1).std(),\n",
        "        responses_3pl.iloc[:, 1:].sum(axis=1).std()\n",
        "    ],\n",
        "    'Avg Difficulty': [\n",
        "        params_1pl['difficulty'].mean(),\n",
        "        params_2pl['difficulty'].mean(),\n",
        "        params_3pl['difficulty'].mean()\n",
        "    ],\n",
        "    'Avg Discrimination': [\n",
        "        params_1pl['discrimination'].mean(),\n",
        "        params_2pl['discrimination'].mean(),\n",
        "        params_3pl['discrimination'].mean()\n",
        "    ],\n",
        "    'Avg Guessing': [\n",
        "        params_1pl['guessing'].mean(),\n",
        "        params_2pl['guessing'].mean(),\n",
        "        params_3pl['guessing'].mean()\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"=== MODEL COMPARISON ===\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Score distributions\n",
        "ax = axes[0]\n",
        "ax.boxplot([responses_1pl.iloc[:, 1:].sum(axis=1), \n",
        "            responses_2pl.iloc[:, 1:].sum(axis=1),\n",
        "            responses_3pl.iloc[:, 1:].sum(axis=1)],\n",
        "           labels=['1PL', '2PL', '3PL'])\n",
        "ax.set_title('Score Distributions by Model', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Total Score')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Difficulty distributions\n",
        "ax = axes[1]\n",
        "ax.boxplot([params_1pl['difficulty'], params_2pl['difficulty'], params_3pl['difficulty']],\n",
        "           labels=['1PL', '2PL', '3PL'])\n",
        "ax.set_title('Difficulty Distributions by Model', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Difficulty (b)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Discrimination distributions\n",
        "ax = axes[2]\n",
        "ax.boxplot([params_1pl['discrimination'], params_2pl['discrimination'], params_3pl['discrimination']],\n",
        "           labels=['1PL', '2PL', '3PL'])\n",
        "ax.set_title('Discrimination Distributions by Model', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Discrimination (a)')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Model comparison complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine correlations between different variables in our IRT data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "print(\"=== CORRELATION ANALYSIS ===\")\n",
        "\n",
        "# Correlations with student scores\n",
        "student_scores = responses_3pl.iloc[:, 1:].sum(axis=1)\n",
        "ability_score_corr = np.corrcoef(abilities_3pl, student_scores)[0, 1]\n",
        "print(f\"\\nCorrelation between ability and total score: {ability_score_corr:.3f}\")\n",
        "\n",
        "# Item parameter correlations\n",
        "item_response_rates = responses_3pl.iloc[:, 1:].mean()\n",
        "difficulty_response_corr = params_3pl['difficulty'].corr(item_response_rates)\n",
        "discrimination_response_corr = params_3pl['discrimination'].corr(item_response_rates)\n",
        "guessing_response_corr = params_3pl['guessing'].corr(item_response_rates)\n",
        "\n",
        "print(f\"\\nItem parameter correlations with response rate:\")\n",
        "print(f\"  Difficulty vs Response rate: {difficulty_response_corr:.3f}\")\n",
        "print(f\"  Discrimination vs Response rate: {discrimination_response_corr:.3f}\")\n",
        "print(f\"  Guessing vs Response rate: {guessing_response_corr:.3f}\")\n",
        "\n",
        "# Create correlation heatmap for item parameters\n",
        "item_data = pd.DataFrame({\n",
        "    'Difficulty': params_3pl['difficulty'],\n",
        "    'Discrimination': params_3pl['discrimination'],\n",
        "    'Guessing': params_3pl['guessing'],\n",
        "    'Response_Rate': item_response_rates\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(item_data.corr(), annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Item Parameter Correlation Matrix', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nâœ… Correlation analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Summary and Insights\n",
        "\n",
        "Based on our comprehensive data exploration, here are the main insights:\n",
        "\n",
        "### Data Quality\n",
        "âœ… **All data quality checks passed** - No missing values, correct data types, valid ranges\n",
        "\n",
        "### Statistical Insights\n",
        "- Student abilities follow approximately normal distribution\n",
        "- Item parameters are well-distributed across their expected ranges\n",
        "- Strong positive correlation between student ability and total score\n",
        "\n",
        "### Model Differences\n",
        "- **1PL Model**: Simplest, assumes equal discrimination across items\n",
        "- **2PL Model**: Adds discrimination parameter for item quality variation\n",
        "- **3PL Model**: Most comprehensive, includes guessing parameter\n",
        "\n",
        "### Next Steps\n",
        "The data is **clean and ready** for advanced analysis and modeling in the application notebook!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Findings from Exploratory Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
